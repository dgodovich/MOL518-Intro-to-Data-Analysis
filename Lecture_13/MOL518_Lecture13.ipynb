{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaevitz/MOL518-Intro-to-Data-Analysis/blob/main/Lecture_13/MOL518_Lecture13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In colab run this cell first to setup the file structure!\n",
        "%cd /content\n",
        "!rm -rf MOL518-Intro-to-Data-Analysis\n",
        "\n",
        "!git clone https://github.com/shaevitz/MOL518-Intro-to-Data-Analysis.git\n",
        "%cd MOL518-Intro-to-Data-Analysis/Lecture_13"
      ],
      "metadata": {
        "id": "0U_kh6fX69uf"
      },
      "id": "0U_kh6fX69uf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1H2zFHn6RsA"
      },
      "source": [
        "\n",
        "# Lecture 13: Curve Fitting Beyond Linear Regression\n",
        "\n",
        "In this class, we will learn how to fit nonlinear curves to biological datasents and plot them in Python using Jupyter Notebooks running in Google Colab.\n",
        "\n",
        "**Learning objectives**\n",
        "- Understand when and why nonlinear models are needed (vs. linearization)\n",
        "- Learn how to fit nonlinear models to data using `scipy.optimize.curve_fit`\n",
        "- Interpret parameter estimates and covariance\n",
        "- Evaluate the curve fits using residuals, $R^2$, and Akaike Information Criterion (AIC)\n",
        "- Apply curve fitting to common biological models: exponential growth, Michaelis–Menten kinetics, Hill equations\n",
        "\n",
        "> Tip: Run cells in order. Each section is independent but reuses utility functions defined below.\n"
      ],
      "id": "c1H2zFHn6RsA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WA233CkL6RsC"
      },
      "source": [
        "\n",
        "## Setup & utilities\n",
        "This cell imports libraries and defines helper functions for metrics and plotting.\n"
      ],
      "id": "WA233CkL6RsC"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiWhPw2-6RsD"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# import necessary libraries: numpy, pandas, matplotlib, scipy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import curve_fit\n",
        "\n",
        "# Matplotlib defaults\n",
        "plt.rcParams.update({\n",
        "    \"figure.figsize\": (6.5, 4.2),\n",
        "    \"axes.grid\": True,\n",
        "    \"grid.alpha\": 0.25,\n",
        "})\n",
        "\n",
        "# Reproducibility\n",
        "np.random.seed(42) # use the same random seed each time for reproducible results\n",
        "\n",
        "# ---------- Helper functions ----------\n",
        "\n",
        "# this function calculates the r^2 value for the curve fit\n",
        "def r2_score(y_true, y_pred):\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_pred = np.asarray(y_pred)\n",
        "    ss_res = np.sum((y_true - y_pred)**2)\n",
        "    ss_tot = np.sum((y_true - np.mean(y_true))**2)\n",
        "    return 1 - ss_res/ss_tot\n",
        "\n",
        "# this function calculates the Akaike Information Criterion (AIC) for the fit\n",
        "def aic(y_true, y_pred, k):\n",
        "    # Akaike Information Criterion for least-squares fits.\n",
        "    # k = number of free parameters\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_pred = np.asarray(y_pred)\n",
        "    n = len(y_true)\n",
        "    rss = np.sum((y_true - y_pred)**2)\n",
        "    return 2*k + n * np.log(rss / n)\n",
        "\n",
        "# this function plots the curve fits\n",
        "def plot_fit(x, y, model, popt, xlabel=\"x\", ylabel=\"y\", title=\"Fit\"):\n",
        "    x = np.asarray(x)\n",
        "    y = np.asarray(y)\n",
        "    xs = np.linspace(np.min(x), np.max(x), 400)\n",
        "    plt.scatter(x, y, s=32, alpha=0.9, label=\"Data\")\n",
        "    plt.plot(xs, model(xs, *popt), c=\"crimson\", lw=2.0, label=\"Model fit\")\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# this function will help us plot the residuals after doing curve fitting\n",
        "def plot_residuals(x, residuals, xlabel=\"x\"):\n",
        "    plt.axhline(0, color='k', lw=1, alpha=0.6)\n",
        "    plt.scatter(x, residuals, s=28)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(\"Residuals (y - ŷ)\")\n",
        "    plt.title(\"Residual plot\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"Libraries imported & utilities ready.\")\n"
      ],
      "id": "PiWhPw2-6RsD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsExFdNI6RsE"
      },
      "source": [
        "\n",
        "## Motivation: Why nonlinear models?\n",
        "Many biological relationships are nonlinear:\n",
        "\n",
        "- **Exponential Growth/decay:** $y = A e^{kt}$ or logistic growth\n",
        "$y = \\frac{K}{1 + e^{-r(t-t_0)}}$\n",
        "\n",
        "- **Enzyme kinetics (Michaelis–Menten):**\n",
        "$v = \\frac{V_\\max [S]}{K_m + [S]}$\n",
        "\n",
        "- **Cooperative binding (Hill):**\n",
        "$Y = \\frac{[L]^n}{K_d^n + [L]^n}$\n",
        "\n",
        "Historically, researchers *linearized* these models (e.g., Lineweaver–Burk) but that can *distort errors* and bias estimates. The current best practice is to fit the nonlinear model *directly* to the data by using least squares or maximum likelihood methods.\n",
        "\n",
        "For the purposes of this class, we will focus on least squares approaches, as they are simpler to teach, and are the method of choice for simple nonlinear curve fitting.\n",
        "\n",
        "**Note:** We discussed least squares methods in the last class in the context of linear fitting, but it is also really useful for nonlinear fitting! The way the error is calculated is the same.\n"
      ],
      "id": "vsExFdNI6RsE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvrXmhYI6RsF"
      },
      "source": [
        "\n",
        "## Nonlinear regression with `scipy.optimize.curve_fit`\n",
        "Key ideas:\n",
        "- Define a Python function `f(x, *theta)` for your model.\n",
        "- Provide **initial guesses** `p0` (crucial for convergence).\n",
        "- Optional **bounds** can constrain parameters (e.g., positivity for concentrations).\n",
        "- `curve_fit` returns `popt` (best-fit params) and `pcov` (covariance matrix).\n",
        "- Standard errors are `se = sqrt(diag(pcov))` if the model is well-specified.\n"
      ],
      "id": "BvrXmhYI6RsF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZcPj8nW6RsG"
      },
      "source": [
        "\n",
        "## Evaluating fit quality\n",
        "\n",
        "Once you have made a fit, the next critical step is to determine how good your fit is. There are four key metrics to look at when evaluating a nonlinear curve fit.\n",
        "\n",
        "- **Residuals:** should be structureless (no systematic biases or trends) and roughly homoscedastic (equal variance across the dataset).\n",
        "- **$R^2$:** can be thought of as the fraction of variance explained by the fit. Use this metric cautiously for nonlinear models, as $R^2$ is inherently a linear metric. If the dataset is only a little bit nonlinear, $R^2$ might be okay to use sparingly.\n",
        "- **AIC:** supports model comparison; lower is better for comparable datasets. This is a complicated metric to explain, but feel free to read more about it [here](https://en.wikipedia.org/wiki/Akaike_information_criterion).\n",
        "- **Parameter uncertainty:** use `pcov` → standard errors; consider calculating confidence intervals using bootstrapping."
      ],
      "id": "ZZcPj8nW6RsG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhXq-m_V6RsF"
      },
      "source": [
        "\n",
        "## Example 1: Exponential growth\n",
        "\n",
        "For this very simple example, we will be using synthetic data, generated by adding random, normally distributed noise to the data.\n",
        "\n",
        "Synthetic data: $OD_{600} = A e^{kt} + \\epsilon$\n",
        "\n",
        "Here, $\\epsilon$ denotes normally distributed noise that we are adding to the data to simlulate measurment error in experimental data.\n"
      ],
      "id": "UhXq-m_V6RsF"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Bp_eHZZ6RsF"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "# ----- Generate synthetic data -----\n",
        "t = np.linspace(0, 10, 50)\n",
        "A_true, k_true = 0.03, 0.40\n",
        "OD600 = A_true * np.exp(k_true * t) + np.random.normal(0, 0.07, size=t.size)\n",
        "\n",
        "# ----- Model -----\n",
        "def exp_model(t, A, k):\n",
        "    return A * np.exp(k * t)\n",
        "\n",
        "# ----- Fit -----\n",
        "pnot = [1.0, 0.1]  # initial guesses\n",
        "popt, pcov = curve_fit(exp_model, t, OD600, p0=pnot)\n",
        "A_fit, k_fit = popt # this unpacks popt, which is the output of the curve fitting function\n",
        "perr = np.sqrt(np.diag(pcov))\n",
        "\n",
        "print(f\"A = {A_fit:.3f} ± {perr[0]:.3f}\")\n",
        "print(f\"k = {k_fit:.3f} ± {perr[1]:.3f}\")\n",
        "\n",
        "# ----- Evaluate -----\n",
        "OD600hat = exp_model(t, *popt)\n",
        "print(f\"R^2 = {r2_score(OD600, OD600hat):.3f}\")\n",
        "print(f\"AIC = {aic(OD600, OD600hat, k=2):.2f}\")\n",
        "\n",
        "# ----- Plot -----\n",
        "plot_fit(t, OD600, exp_model, popt, xlabel=\"Time (hours)\", ylabel=r'$OD_{600}$', title=\"Exponential growth fit\")\n",
        "residuals = OD600 - OD600hat\n",
        "plot_residuals(t, residuals, xlabel=\"Time (hours)\")\n"
      ],
      "id": "_Bp_eHZZ6RsF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions related to Example 1\n",
        "\n",
        "1. How well does the model fit the data (based on visual inspection of the graph)?\n",
        "\n",
        "**[Your answer goes here]**\n",
        "\n",
        "2. How much variation is there in the parameter estimates?\n",
        "\n",
        "**[Your answer goes here]**\n",
        "\n",
        "3. What do the residuals look like? Are structureless and roughly homoscedastic?\n",
        "\n",
        "**[Your answer goes here]**"
      ],
      "metadata": {
        "id": "C6PuBRXz_JjG"
      },
      "id": "C6PuBRXz_JjG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUbW1YAS6RsF"
      },
      "source": [
        "\n",
        "## Exercise 1: Michaelis–Menten (enzyme kinetics)\n",
        "\n",
        "I'm sure you are all at least somewhat familiar with the Michaelis-Menten equations from your undergraduate studies. What you may not have been taught is that they were the first example of quantitative modeling in biology, and that they were figured out long before we had any ideas about how enzymes actually worked **(back in 1913!!)**. For more on this fascinating history, check out [this link](https://www.sciencedirect.com/science/article/pii/S2213020914000627).\n",
        "\n",
        "For this exercise, I have left the \"Model\" part blank. You will need to define a function ```mm_model``` using the formula below:\n",
        "\n",
        "Model: $v = \\dfrac{V_{\\max} [S]}{K_m + [S]}$.\n",
        "\n",
        "Parameters:\n",
        "- $V_{\\max}$: maximum reaction velocity\n",
        "- $K_m$: substrate concentration at half-max velocity\n",
        "\n",
        "Please do not use generative AI for this exercise!"
      ],
      "id": "sUbW1YAS6RsF"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YX7Kilw6RsF"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "# ----- Generate synthetic data -----\n",
        "S = np.linspace(0.05, 10.0, 30)\n",
        "Vmax_true, Km_true = 5.0, 2.0\n",
        "v = Vmax_true * S / (Km_true + S) + np.random.normal(0, 0.4, size=S.size)\n",
        "\n",
        "# ----- Model -----\n",
        "def mm_model(S, Vmax, Km):\n",
        "    return Vmax * S / (Km + S)\n",
        "\n",
        "# ----- Fit -----\n",
        "p0 = [1.0, 1.0]\n",
        "popt, pcov = curve_fit(mm_model, S, v, p0=p0, bounds=(0, np.inf))\n",
        "Vmax_fit, Km_fit = popt\n",
        "perr = np.sqrt(np.diag(pcov))\n",
        "\n",
        "print(f\"Vmax = {Vmax_fit:.3f} ± {perr[0]:.3f}\")\n",
        "print(f\"Km   = {Km_fit:.3f} ± {perr[1]:.3f}\")\n",
        "\n",
        "# ----- Evaluate & plot -----\n",
        "vhat = mm_model(S, *popt)\n",
        "print(f\"R^2 = {r2_score(v, vhat):.3f}\")\n",
        "print(f\"AIC = {aic(v, vhat, k=2):.2f}\")\n",
        "plot_fit(S, v, mm_model, popt, xlabel=\"[S] (pM)\", ylabel=\"v (nM/s)\", title=\"Michaelis–Menten fit\")\n",
        "plot_residuals(S, v - vhat, xlabel=\"[S] (pM)\")\n"
      ],
      "id": "2YX7Kilw6RsF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions related to Exercise 1\n",
        "\n",
        "1. How well does the model fit the data (based on visual inspection of the graph)?\n",
        "\n",
        "**[Your answer goes here]**\n",
        "\n",
        "2. How much variation is there in the parameter estimates?\n",
        "\n",
        "**[Your answer goes here]**\n",
        "\n",
        "3. What do the residuals look like? Are structureless and roughly homoscedastic?\n",
        "\n",
        "**[Your answer goes here]**"
      ],
      "metadata": {
        "id": "8wQcHX9jI7wu"
      },
      "id": "8wQcHX9jI7wu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSURsC0R6RsG"
      },
      "source": [
        "\n",
        "## Excercise 2: Hill equation (ligand binding)\n",
        "\n",
        "I expect that someo of you will have heard of the Hill equation, which is a simple model for cooperative (or non-cooperative) binding between a ligand and a macromolecule (e.g., a protein or nucleic acid).\n",
        "\n",
        "For this exercise, I have left both the Model and the Fit parts blank for you to fill in as an exercise. You will need to define a model ```hill``` as well as write code to do the curve fitting.\n",
        "\n",
        "Model: $Y = \\dfrac{[L]^n}{K_d^n + [L]^n}$, where $n$ is the Hill (cooperativity) coefficient.\n",
        "\n",
        "- $K_d$: apparent dissociation constant (ligand at half-occupancy)\n",
        "- $n>1$: positive cooperativity; $n=1$: noncooperative; $n<1$: negative cooperativity\n",
        "\n",
        "Please do not use generative AI for this exercise!\n"
      ],
      "id": "fSURsC0R6RsG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAlfZ74o6RsG"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "# ----- Generate synthetic data -----\n",
        "L = np.logspace(-2, 2, 40)\n",
        "Kd_true, n_true = 5.0, 2.0\n",
        "Y = L**n_true / (Kd_true**n_true + L**n_true) + np.random.normal(0, 0.05, size=L.size)\n",
        "\n",
        "# ----- Model -----\n",
        "\n",
        "def hill(L, Kd, n):\n",
        "    return L**n / (Kd**n + L**n)\n",
        "\n",
        "# ----- Fit -----\n",
        "pnot = [1.0, 1.0]\n",
        "popt, pcov = curve_fit(hill, L, Y, p0=pnot, bounds=(0, [np.inf, 10]))\n",
        "Kd_fit, n_fit = popt\n",
        "perr = np.sqrt(np.diag(pcov))\n",
        "\n",
        "print(f\"Kd = {Kd_fit:.3f} ± {perr[0]:.3f}\")\n",
        "print(f\"n  = {n_fit:.3f} ± {perr[1]:.3f}\")\n",
        "\n",
        "# ----- Evaluate & plot -----\n",
        "Yhat = hill(L, *popt)\n",
        "print(f\"R^2 = {r2_score(Y, Yhat):.3f}\")\n",
        "print(f\"AIC = {aic(Y, Yhat, k=2):.2f}\")\n",
        "plt.semilogx()\n",
        "plot_fit(L, Y, hill, popt, xlabel=\"[L] (nM)\", ylabel=\"Y (fraction bound)\", title=\"Hill binding curve fit\")\n",
        "plot_residuals(L, Y - Yhat, xlabel=\"[L] (nM)\")\n"
      ],
      "id": "sAlfZ74o6RsG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions related to Exercise 2\n",
        "\n",
        "1. How well does the model fit the data (based on visual inspection of the graph)?\n",
        "\n",
        "**[Your answer goes here]**\n",
        "\n",
        "2. How much variation is there in the parameter estimates?\n",
        "\n",
        "**[Your answer goes here]**\n",
        "\n",
        "3. What do the residuals look like? Are structureless and roughly homoscedastic?\n",
        "\n",
        "**[Your answer goes here]**"
      ],
      "metadata": {
        "id": "C0AV9O8bLPSJ"
      },
      "id": "C0AV9O8bLPSJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Selection: What if I don't know which curve to fit to my data?\n",
        "\n"
      ],
      "metadata": {
        "id": "B2ZX6rAqfl4d"
      },
      "id": "B2ZX6rAqfl4d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 2: **??? data**"
      ],
      "metadata": {
        "id": "cVyerMTDhet3"
      },
      "id": "cVyerMTDhet3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3: **??? data**"
      ],
      "metadata": {
        "id": "vE7B9qPFfUTm"
      },
      "id": "vE7B9qPFfUTm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZRX-Q3T6RsI"
      },
      "source": [
        "\n",
        "## Optional: Save datasets to CSV\n",
        "This cell regenerates the four exercise datasets and saves them as CSV files so you can practice loading from files.\n"
      ],
      "id": "MZRX-Q3T6RsI"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lrO2vSz6RsI"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "# Regenerate and save datasets\n",
        "# Exercise 1\n",
        "np.random.seed(0)\n",
        "t = np.linspace(0, 20, 40)\n",
        "y = 50 * np.exp(-0.3 * t) + np.random.normal(0, 2.0, size=t.size)\n",
        "pd.DataFrame({\"t\": t, \"y\": y}).to_csv(\"exercise1_decay.csv\", index=False)\n",
        "\n",
        "# Exercise 2\n",
        "np.random.seed(2)\n",
        "t = np.linspace(0, 12, 50)\n",
        "K_true, r_true, t0_true = 1.0, 1.2, 6.0\n",
        "y = K_true / (1 + np.exp(-r_true * (t - t0_true))) + np.random.normal(0, 0.05, size=t.size)\n",
        "pd.DataFrame({\"t\": t, \"y\": y}).to_csv(\"exercise2_logistic.csv\", index=False)\n",
        "\n",
        "# Exercise 3\n",
        "S = np.linspace(0.1, 15, 25)\n",
        "v = 8 * S / (3 + S) + np.random.normal(0, 0.3, size=S.size)\n",
        "pd.DataFrame({\"S\": S, \"v\": v}).to_csv(\"exercise3_mm.csv\", index=False)\n",
        "\n",
        "# Exercise 4\n",
        "L = np.logspace(-1, 2, 30)\n",
        "Y = L**1.8 / (7**1.8 + L**1.8) + np.random.normal(0, 0.03, size=L.size)\n",
        "pd.DataFrame({\"L\": L, \"Y\": Y}).to_csv(\"exercise4_hill.csv\", index=False)\n",
        "\n",
        "print(\"Saved: exercise1_decay.csv, exercise2_logistic.csv, exercise3_mm.csv, exercise4_hill.csv\")\n"
      ],
      "id": "8lrO2vSz6RsI"
    }
  ]
}